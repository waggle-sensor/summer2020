{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Camera Data Test"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Delcare Paths"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "working_dir = \"/Volumes/Samsung_T5/WeatherNet_V2\"\n",
        "data_dir = working_dir + \"/npy_dataset\"\n",
        "flir_path = data_dir + \"/flir\"\n",
        "top_path = data_dir + \"/top\"\n",
        "bottom_path = data_dir + \"/bottom\"\n",
        "weather_data_dir = data_dir + \"/weather/30_min\"\n",
        "weather_data_input_path = weather_data_dir + \"/scaled_30_min_weather.csv\"\n",
        "weather_data_labels_path = weather_data_dir + \"/30_labels.csv\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "shell.execute_reply": "2020-07-13T20:44:24.835Z",
          "iopub.status.busy": "2020-07-13T20:44:24.861Z",
          "iopub.execute_input": "2020-07-13T20:44:24.868Z",
          "iopub.status.idle": "2020-07-13T20:44:24.877Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Modules"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import trange\n",
        "\n",
        "# Data Manipulation\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import glob \n",
        "\n",
        "# Numeric operations \n",
        "import numpy as np \n",
        "from random import shuffle \n",
        "from itertools import chain \n",
        "\n",
        "# Data Generator\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.utils import to_categorical \n",
        "\n",
        "# Deep Learning Layers\n",
        "from tensorflow.keras.layers import Input, ConvLSTM2D, Concatenate,Dropout,TimeDistributed, SeparableConv2D, GlobalAveragePooling2D,Dense,GlobalAveragePooling3D,MaxPooling2D, LSTM\n",
        "\n",
        "# General TF and Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from sklearn.metrics import classification_report"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-07-13T20:44:24.889Z",
          "iopub.execute_input": "2020-07-13T20:44:24.896Z",
          "iopub.status.idle": "2020-07-13T20:44:28.919Z",
          "shell.execute_reply": "2020-07-13T20:44:28.987Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generator Class"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "class SeqDataGenerator(Sequence):\n",
        "    def __init__(self,sample_ids,labels,seq_len,df_data,flir_path,top_path,\n",
        "                  bottom_path,batch_size=32,n_class=3,dim=(4,3,480,640),shuffle=True):\n",
        "        \n",
        "        self.dim = dim \n",
        "        self.batch_size = batch_size\n",
        "        self.sample_ids = sample_ids\n",
        "        self.labels = labels\n",
        "        self.n_class = n_class \n",
        "        self.shuffle = shuffle\n",
        "        \n",
        "        self.seq_len = seq_len\n",
        "        self.df_data = df_data\n",
        "        \n",
        "        self.flir_path = flir_path\n",
        "        self.top_path = top_path\n",
        "        self.bottom_path = bottom_path\n",
        "        \n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.sample_ids))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)        \n",
        "        \n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.sample_ids) / self.batch_size))  \n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        sample_ids_temp = [self.sample_ids[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(sample_ids_temp,indexes)\n",
        "\n",
        "        return X, y   \n",
        "        \n",
        "    def __data_generation(self, sample_ids_temp,indexes):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X_flir = np.empty((self.batch_size, *self.dim))\n",
        "        X_bottom = np.empty((self.batch_size, *self.dim))\n",
        "        X_top = np.empty((self.batch_size, *self.dim))\n",
        "        \n",
        "        # X_df : (n_samples, seq_len, self.df_data.shape[1])\n",
        "        X_df = np.empty((self.batch_size, self.seq_len, self.df_data.shape[1])) \n",
        "        \n",
        "        y = np.empty((self.batch_size,self.n_class), dtype=int)\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(sample_ids_temp):\n",
        "            # Store sample\n",
        "            X_flir[i,] = np.load(self.flir_path + '/' + ID + \".npy\")\n",
        "            X_bottom[i,] = np.load(self.bottom_path + '/' + ID + \".npy\")\n",
        "            X_top[i,] = np.load(self.top_path + '/' + ID + \".npy\") \n",
        "            \n",
        "        for i, ID in enumerate(sample_ids_temp):\n",
        "            # Store sample\n",
        "            idx = np.where(self.df_data.index == ID)\n",
        "            idx = idx[0][0]\n",
        "            X_df[i,] = self.df_data.iloc[idx-self.seq_len+1:idx+1,:]\n",
        "\n",
        "        for i , idx in enumerate(sample_ids_temp):    \n",
        "            # Store class\n",
        "            a = self.labels.loc[idx].values\n",
        "            y[i,:] = self.labels.loc[idx].values\n",
        "            \n",
        "        return [X_flir,X_bottom,X_top,X_df], y    "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-07-13T20:44:28.934Z",
          "iopub.execute_input": "2020-07-13T20:44:28.942Z",
          "iopub.status.idle": "2020-07-13T20:44:28.955Z",
          "shell.execute_reply": "2020-07-13T20:44:28.994Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get names of images"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "flir_files = [os.path.basename(file) for i,file in\\\n",
        "                    enumerate(glob.glob(flir_path+\"/*.npy\"))]\n",
        "top_files = [os.path.basename(file) for i,file in\\\n",
        "                    enumerate(glob.glob(top_path+\"/*.npy\"))]\n",
        "bottom_files = [os.path.basename(file) for i,file in\\\n",
        "                    enumerate(glob.glob(bottom_path+\"/*.npy\"))]\n",
        "\n",
        "flir_files.sort()\n",
        "top_files.sort()\n",
        "bottom_files.sort()\n",
        "\n",
        "if flir_files == top_files == bottom_files:\n",
        "    print(\"ALL SAMPLES FOR EACH CLASS ARE MATCHING!\")\n",
        "    \n",
        "image_names = bottom_files    "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-07-13T20:44:28.967Z",
          "iopub.execute_input": "2020-07-13T20:44:28.974Z",
          "iopub.status.idle": "2020-07-13T20:44:29.151Z",
          "shell.execute_reply": "2020-07-13T20:44:29.187Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Weather df"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "weather_df = pd.read_csv(weather_data_input_path)\n",
        "weather_df.index = weather_df[\"Unnamed: 0\"]\n",
        "weather_df.drop([\"Unnamed: 0\"],axis=1,inplace=True)\n",
        "weather_df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-07-13T20:44:29.166Z",
          "iopub.execute_input": "2020-07-13T20:44:29.176Z",
          "iopub.status.idle": "2020-07-13T20:44:29.382Z",
          "shell.execute_reply": "2020-07-13T20:44:29.723Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weather df Columns\n",
        "[\"Average 60 m temperature\",\n",
        "\"Average 60 m wind speed\",\n",
        "\"Vector-averaged 60 m wind speed\",\n",
        "\"Vector-averaged 60 m wind direction\",\n",
        "\"Standard deviation of 60 m wind direction\",\n",
        "\"Total precipitaion for the period\",\n",
        "\"Estimated heat flux\",\n",
        "\"Estimated friction velocity\",\n",
        "\"Average 10 m temperature\",\n",
        "\"Average 10 m wind speed\",\n",
        "\"Vector-averaged 10 m wind speed\",\n",
        "\"Vector-averaged 10 m wind direction\",\n",
        "\"Standard deviation of 10 m wind direction\",\n",
        "\"Average global irrradiation\",\n",
        "\"Average net radiation\",\n",
        "\"Estimated surface roughness length\",\n",
        "\"Average 10 m vapor pressure\",\n",
        "\"Average 10 m dew point temperature\",\n",
        "\"target\",\n",
        "\"month_1\",\n",
        "\"month_2\",\n",
        "\"month_3\",\n",
        "\"month_4\",\n",
        "\"month_5\",\n",
        "\"hour_min_00_00\",\n",
        "\"hour_min_00_15\",\n",
        "\"hour_min_00_30\",\n",
        "\"hour_min_00_45\",\n",
        "\"hour_min_01_00\",\n",
        "\"hour_min_01_15\",\n",
        "\"hour_min_01_30\",\n",
        "\"hour_min_01_45\",\n",
        "\"hour_min_02_00\",\n",
        "\"hour_min_02_15\",\n",
        "\"hour_min_02_30\",\n",
        "\"hour_min_02_45\",\n",
        "\"hour_min_03_00\",\n",
        "\"hour_min_03_15\",\n",
        "\"hour_min_03_30\",\n",
        "\"hour_min_03_45\",\n",
        "\"hour_min_04_00\",\n",
        "\"hour_min_04_15\",\n",
        "\"hour_min_04_30\",\n",
        "\"hour_min_04_45\",\n",
        "\"hour_min_05_00\",\n",
        "\"hour_min_05_15\",\n",
        "\"hour_min_05_30\",\n",
        "\"hour_min_05_45\",\n",
        "\"hour_min_06_00\",\n",
        "\"hour_min_06_15\",\n",
        "\"hour_min_06_30\",\n",
        "\"hour_min_06_45\",\n",
        "\"hour_min_07_00\",\n",
        "\"hour_min_07_15\",\n",
        "\"hour_min_07_30\",\n",
        "\"hour_min_07_45\",\n",
        "\"hour_min_08_00\",\n",
        "\"hour_min_08_15\",\n",
        "\"hour_min_08_30\",\n",
        "\"hour_min_08_45\",\n",
        "\"hour_min_09_00\",\n",
        "\"hour_min_09_15\",\n",
        "\"hour_min_09_30\",\n",
        "\"hour_min_09_45\",\n",
        "\"hour_min_10_00\",\n",
        "\"hour_min_10_15\",\n",
        "\"hour_min_10_30\",\n",
        "\"hour_min_10_45\",\n",
        "\"hour_min_11_00\",\n",
        "\"hour_min_11_15\",\n",
        "\"hour_min_11_30\",\n",
        "\"hour_min_11_45\",\n",
        "\"hour_min_12_00\",\n",
        "\"hour_min_12_15\",\n",
        "\"hour_min_12_30\",\n",
        "\"hour_min_12_45\",\n",
        "\"hour_min_13_00\",\n",
        "\"hour_min_13_15\",\n",
        "\"hour_min_13_30\",\n",
        "\"hour_min_13_45\",\n",
        "\"hour_min_14_00\",\n",
        "\"hour_min_14_15\",\n",
        "\"hour_min_14_30\",\n",
        "\"hour_min_14_45\",\n",
        "\"hour_min_15_00\",\n",
        "\"hour_min_15_15\",\n",
        "\"hour_min_15_30\",\n",
        "\"hour_min_15_45\",\n",
        "\"hour_min_16_00\",\n",
        "\"hour_min_16_15\",\n",
        "\"hour_min_16_30\",\n",
        "\"hour_min_16_45\",\n",
        "\"hour_min_17_00\",\n",
        "\"hour_min_17_15\",\n",
        "\"hour_min_17_30\",\n",
        "\"hour_min_17_45\",\n",
        "\"hour_min_18_00\",\n",
        "\"hour_min_18_15\",\n",
        "\"hour_min_18_30\",\n",
        "\"hour_min_18_45\",\n",
        "\"hour_min_19_00\",\n",
        "\"hour_min_19_15\",\n",
        "\"hour_min_19_30\",\n",
        "\"hour_min_19_45\",\n",
        "\"hour_min_20_00\",\n",
        "\"hour_min_20_15\",\n",
        "\"hour_min_20_30\",\n",
        "\"hour_min_20_45\",\n",
        "\"hour_min_21_00\",\n",
        "\"hour_min_21_15\",\n",
        "\"hour_min_21_30\",\n",
        "\"hour_min_21_45\",\n",
        "\"hour_min_22_00\",\n",
        "\"hour_min_22_15\",\n",
        "\"hour_min_22_30\",\n",
        "\"hour_min_22_45\",\n",
        "\"hour_min_23_00\",\n",
        "\"hour_min_23_15\",\n",
        "\"hour_min_23_30\",\n",
        "\"hour_min_23_45\"]"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drop columns depending on test"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "drop_col = [\"Average 60 m temperature\", \"Average 60 m wind speed\",\n",
        "\"Vector-averaged 60 m wind speed\", \"Vector-averaged 60 m wind direction\",\n",
        "\"Standard deviation of 60 m wind direction\", \"Total precipitaion for the period\",\n",
        "\"Estimated heat flux\", \"Estimated friction velocity\", \"Average 10 m temperature\",\n",
        "\"Average 10 m wind speed\", \"Vector-averaged 10 m wind speed\",\n",
        "\"Vector-averaged 10 m wind direction\", \"Standard deviation of 10 m wind direction\",\n",
        "\"Average global irrradiation\", \"Average net radiation\", \"Estimated surface roughness length\",\n",
        "\"Average 10 m vapor pressure\", \"Average 10 m dew point temperature\"]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-07-13T20:44:29.396Z",
          "iopub.execute_input": "2020-07-13T20:44:29.405Z",
          "iopub.status.idle": "2020-07-13T20:44:29.421Z",
          "shell.execute_reply": "2020-07-13T20:44:29.731Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weather_df.drop(drop_col,axis=1,inplace=True)\n",
        "weather_df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-07-13T20:44:29.433Z",
          "iopub.execute_input": "2020-07-13T20:44:29.443Z",
          "iopub.status.idle": "2020-07-13T20:44:29.463Z",
          "shell.execute_reply": "2020-07-13T20:44:29.738Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load labels"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "labels = pd.read_csv(weather_data_labels_path)\n",
        "labels.index = labels['time_stamp']\n",
        "labels.drop(['time_stamp'],axis=1,inplace=True)\n",
        "labels.columns = ['target']\n",
        "labels.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-07-13T20:44:29.478Z",
          "iopub.execute_input": "2020-07-13T20:44:29.490Z",
          "iopub.status.idle": "2020-07-13T20:44:29.515Z",
          "shell.execute_reply": "2020-07-13T20:44:29.744Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_index = [name.split(\".\")[0] for i,name in enumerate(image_names)]\n",
        "diff = set(label_index)-set(labels.index)\n",
        "for i,label in enumerate(list(diff)):\n",
        "    if label in label_index:\n",
        "        label_index.remove(label)\n",
        "labels = labels.loc[label_index]\n",
        "\n",
        "labels = pd.concat([labels,pd.get_dummies(labels['target'], prefix='target')],axis=1)\n",
        "labels.drop(['target'],axis=1, inplace=True)\n",
        "\n",
        "labels.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-07-13T20:44:29.531Z",
          "iopub.execute_input": "2020-07-13T20:44:29.540Z",
          "iopub.status.idle": "2020-07-13T20:44:29.561Z",
          "shell.execute_reply": "2020-07-13T20:44:29.750Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split image file list between train, val, and test"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_names = label_index[:-750-250]\n",
        "train_labels = labels.iloc[:-750-250,:]\n",
        "\n",
        "val_image_names = label_index[-750-250:-750]\n",
        "val_labels = labels.iloc[:-750-250:-750,:]\n",
        "\n",
        "test_image_names = label_index[-750:]\n",
        "test_labels = labels.iloc[-750:,:]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-07-13T20:44:29.579Z",
          "iopub.execute_input": "2020-07-13T20:44:29.588Z",
          "iopub.status.idle": "2020-07-13T20:44:29.604Z",
          "shell.execute_reply": "2020-07-13T20:44:29.759Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Declare Generators"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# dim ~ (# frames per seq, channels, height, width)\n",
        "params = {'dim': (4,3,480,640),\n",
        "          'batch_size': 32,\n",
        "          'n_class': 3,\n",
        "          'shuffle': False}\n",
        "\n",
        "seq_len = 4\n",
        "\n",
        "train_sample_ids = train_labels.index.values\n",
        "train_gen = SeqDataGenerator(train_sample_ids,train_labels,seq_len,weather_df,\\\n",
        "                            flir_path,top_path,bottom_path,**params)\n",
        "\n",
        "val_sample_ids = val_labels.index.values\n",
        "val_gen = SeqDataGenerator(val_sample_ids,val_labels,seq_len,weather_df,\\\n",
        "                            flir_path,top_path,bottom_path,**params)\n",
        "\n",
        "test_sample_ids = test_labels.index.values\n",
        "test_gen = SeqDataGenerator(test_sample_ids,test_labels,seq_len,weather_df,\\\n",
        "                            flir_path,top_path,bottom_path,**params)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-07-13T20:44:29.620Z",
          "iopub.execute_input": "2020-07-13T20:44:29.631Z",
          "iopub.status.idle": "2020-07-13T20:44:29.645Z",
          "shell.execute_reply": "2020-07-13T20:44:29.766Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = train_gen.__getitem__(0)\n",
        "X_flir, X_bottom, X_top, X_df = X[0], X[1], X[2], X[3]\n",
        "print(\"Flir seq shape: \", X_flir.shape)\n",
        "print(\"Bottom seq shape: \", X_bottom.shape)\n",
        "print(\"Top seq shape: \", X_top.shape)\n",
        "print(\"Weather data shape: \", X_df.shape)\n",
        "print(\"Target data shape: \",y.shape) "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-07-13T20:44:29.659Z",
          "iopub.execute_input": "2020-07-13T20:44:29.669Z",
          "iopub.status.idle": "2020-07-13T20:44:32.262Z",
          "shell.execute_reply": "2020-07-13T20:44:32.313Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = test_gen.__getitem__(0)\n",
        "X_flir, X_bottom, X_top, X_df = X[0], X[1], X[2], X[3]\n",
        "print(\"Flir seq shape: \", X_flir.shape)\n",
        "print(\"Bottom seq shape: \", X_bottom.shape)\n",
        "print(\"Top seq shape: \", X_top.shape)\n",
        "print(\"Weather data shape: \", X_df.shape)\n",
        "print(\"Target data shape: \",y.shape) "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-07-13T20:44:32.276Z",
          "iopub.execute_input": "2020-07-13T20:44:32.287Z",
          "iopub.status.idle": "2020-07-13T20:44:34.935Z",
          "shell.execute_reply": "2020-07-13T20:44:34.984Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Declare Model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# shape=(batch_size, time_steps, channels, row, col)\n",
        "input_flir = Input(shape=(seq_len,3,480,640,))\n",
        "x_flir = TimeDistributed(SeparableConv2D(12,(4,4),kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),padding=\"same\"))(input_flir)\n",
        "x_flir = TimeDistributed(MaxPooling2D(pool_size=(2, 2)))(x_flir)\n",
        "\n",
        "input_bottom = Input(shape=(seq_len,3,480,640,))\n",
        "x_bottom = TimeDistributed(SeparableConv2D(12,(4,4),kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),padding=\"same\"))(input_bottom)\n",
        "x_bottom = TimeDistributed(MaxPooling2D(pool_size=(2, 2)))(x_bottom)\n",
        "\n",
        "input_top = Input(shape=(seq_len,3,480,640,))\n",
        "x_top = TimeDistributed(SeparableConv2D(12,(4,4),kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),padding=\"same\"))(input_top)\n",
        "x_top = TimeDistributed(MaxPooling2D(pool_size=(2, 2)))(x_top)\n",
        "\n",
        "input_weather = Input(shape=(seq_len,weather_df.shape[1]))\n",
        "x_LSTM = LSTM(60,kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),return_sequences=False)(input_weather)\n",
        "\n",
        "x_concat = Concatenate(axis=-1)([x_flir,x_bottom,x_top])\n",
        "x_ConvLSTM2D = ConvLSTM2D(16,(4,4),padding=\"same\",kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),return_sequences=True)(x_concat)\n",
        "x_ConvLSTM2D = ConvLSTM2D(32,(2,2),padding=\"same\",kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),return_sequences=False)(x_ConvLSTM2D)\n",
        "\n",
        "x_flat = GlobalAveragePooling2D()(x_ConvLSTM2D)\n",
        "x_flat = Concatenate(axis=-1)([x_flat, x_LSTM])\n",
        "\n",
        "x_flat = Dropout(.2)(x_flat)\n",
        "yh = Dense(3,activation=\"softmax\",kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4))(x_flat)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-07-13T20:44:34.949Z",
          "iopub.execute_input": "2020-07-13T20:44:34.959Z",
          "iopub.status.idle": "2020-07-13T20:44:35.537Z",
          "shell.execute_reply": "2020-07-13T20:44:35.636Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model([input_flir,input_bottom,input_top,input_weather],yh)\n",
        "\n",
        "model.compile(loss=categorical_crossentropy,\n",
        "                 optimizer=Adam(lr=.001),\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "print(model.summary())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-07-13T20:44:35.550Z",
          "iopub.execute_input": "2020-07-13T20:44:35.558Z",
          "iopub.status.idle": "2020-07-13T20:44:35.581Z",
          "shell.execute_reply": "2020-07-13T20:44:35.643Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ann_visualizer.visualize import ann_viz;\n",
        "ann_vis(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-07-13T20:44:35.595Z",
          "iopub.execute_input": "2020-07-13T20:44:35.604Z",
          "iopub.status.idle": "2020-07-13T20:44:35.924Z",
          "shell.execute_reply": "2020-07-13T20:44:36.329Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(working_dir+\"/model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "#model.fit(train_gen,validation_data=val_gen,callbacks = [checkpoint],epochs=1)\n",
        "model.fit_generator(train_gen,validation_data=val_gen,callbacks = [checkpoint],use_multiprocessing=False,epochs=1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-07-13T20:44:35.937Z",
          "iopub.execute_input": "2020-07-13T20:44:35.948Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"weathernet_v2.h5"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yh = model.predict(test_gen)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "target_names = ['low', 'mid', 'high']\n",
        "print(classification_report(np.argmax(test_labels.values[:yh.shape[0],:],axis=1),\\\n",
        "                            np.argmax(yh,axis=1), target_names=target_names))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.24.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}